<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Jaime A. Undurraga" />
  <meta name="dcterms.date" content="2019-06-29" />
  <title>Neural Representation of Interaural Time Differences in Humans – the ITD damping function</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="presentation_files/reveal.js-3.3.0.1/css/reveal.css"/>



<link rel="stylesheet" href="presentation_files/reveal.js-3.3.0.1/css/theme/white.css" id="theme">


  <!-- some tweaks to reveal css -->
  <style type="text/css">
    .reveal h1 { font-size: 2.0em; }
    .reveal h2 { font-size: 1.5em;  }
    .reveal h3 { font-size: 1.25em;	}
    .reveal h4 { font-size: 1em;	}

    .reveal .slides>section,
    .reveal .slides>section>section {
      padding: 0px 0px;
    }



    .reveal table {
      border-width: 1px;
      border-spacing: 2px;
      border-style: dotted;
      border-color: gray;
      border-collapse: collapse;
      font-size: 0.7em;
    }

    .reveal table th {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      font-weight: bold;
      border-style: dotted;
      border-color: gray;
    }

    .reveal table td {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      border-style: dotted;
      border-color: gray;
    }


  </style>

    <style type="text/css">code{white-space: pre;}</style>

    <link rel="stylesheet" href="presentation.css"/>

<!-- Printing and PDF exports -->
<script id="paper-css" type="application/dynamic-css">

/* Default Print Stylesheet Template
   by Rob Glazebrook of CSSnewbie.com
   Last Updated: June 4, 2008

   Feel free (nay, compelled) to edit, append, and
   manipulate this file as you see fit. */


@media print {

	/* SECTION 1: Set default width, margin, float, and
	   background. This prevents elements from extending
	   beyond the edge of the printed page, and prevents
	   unnecessary background images from printing */
	html {
		background: #fff;
		width: auto;
		height: auto;
		overflow: visible;
	}
	body {
		background: #fff;
		font-size: 20pt;
		width: auto;
		height: auto;
		border: 0;
		margin: 0 5%;
		padding: 0;
		overflow: visible;
		float: none !important;
	}

	/* SECTION 2: Remove any elements not needed in print.
	   This would include navigation, ads, sidebars, etc. */
	.nestedarrow,
	.controls,
	.fork-reveal,
	.share-reveal,
	.state-background,
	.reveal .progress,
	.reveal .backgrounds {
		display: none !important;
	}

	/* SECTION 3: Set body font face, size, and color.
	   Consider using a serif font for readability. */
	body, p, td, li, div {
		font-size: 20pt!important;
		font-family: Georgia, "Times New Roman", Times, serif !important;
		color: #000;
	}

	/* SECTION 4: Set heading font face, sizes, and color.
	   Differentiate your headings from your body text.
	   Perhaps use a large sans-serif for distinction. */
	h1,h2,h3,h4,h5,h6 {
		color: #000!important;
		height: auto;
		line-height: normal;
		font-family: Georgia, "Times New Roman", Times, serif !important;
		text-shadow: 0 0 0 #000 !important;
		text-align: left;
		letter-spacing: normal;
	}
	/* Need to reduce the size of the fonts for printing */
	h1 { font-size: 28pt !important;  }
	h2 { font-size: 24pt !important; }
	h3 { font-size: 22pt !important; }
	h4 { font-size: 22pt !important; font-variant: small-caps; }
	h5 { font-size: 21pt !important; }
	h6 { font-size: 20pt !important; font-style: italic; }

	/* SECTION 5: Make hyperlinks more usable.
	   Ensure links are underlined, and consider appending
	   the URL to the end of the link for usability. */
	a:link,
	a:visited {
		color: #000 !important;
		font-weight: bold;
		text-decoration: underline;
	}
	/*
	.reveal a:link:after,
	.reveal a:visited:after {
		content: " (" attr(href) ") ";
		color: #222 !important;
		font-size: 90%;
	}
	*/


	/* SECTION 6: more reveal.js specific additions by @skypanther */
	ul, ol, div, p {
		visibility: visible;
		position: static;
		width: auto;
		height: auto;
		display: block;
		overflow: visible;
		margin: 0;
		text-align: left !important;
	}
	.reveal pre,
	.reveal table {
		margin-left: 0;
		margin-right: 0;
	}
	.reveal pre code {
		padding: 20px;
		border: 1px solid #ddd;
	}
	.reveal blockquote {
		margin: 20px 0;
	}
	.reveal .slides {
		position: static !important;
		width: auto !important;
		height: auto !important;

		left: 0 !important;
		top: 0 !important;
		margin-left: 0 !important;
		margin-top: 0 !important;
		padding: 0 !important;
		zoom: 1 !important;

		overflow: visible !important;
		display: block !important;

		text-align: left !important;
		-webkit-perspective: none;
		   -moz-perspective: none;
		    -ms-perspective: none;
		        perspective: none;

		-webkit-perspective-origin: 50% 50%;
		   -moz-perspective-origin: 50% 50%;
		    -ms-perspective-origin: 50% 50%;
		        perspective-origin: 50% 50%;
	}
	.reveal .slides section {
		visibility: visible !important;
		position: static !important;
		width: auto !important;
		height: auto !important;
		display: block !important;
		overflow: visible !important;

		left: 0 !important;
		top: 0 !important;
		margin-left: 0 !important;
		margin-top: 0 !important;
		padding: 60px 20px !important;
		z-index: auto !important;

		opacity: 1 !important;

		page-break-after: always !important;

		-webkit-transform-style: flat !important;
		   -moz-transform-style: flat !important;
		    -ms-transform-style: flat !important;
		        transform-style: flat !important;

		-webkit-transform: none !important;
		   -moz-transform: none !important;
		    -ms-transform: none !important;
		        transform: none !important;

		-webkit-transition: none !important;
		   -moz-transition: none !important;
		    -ms-transition: none !important;
		        transition: none !important;
	}
	.reveal .slides section.stack {
		padding: 0 !important;
	}
	.reveal section:last-of-type {
		page-break-after: avoid !important;
	}
	.reveal section .fragment {
		opacity: 1 !important;
		visibility: visible !important;

		-webkit-transform: none !important;
		   -moz-transform: none !important;
		    -ms-transform: none !important;
		        transform: none !important;
	}
	.reveal section img {
		display: block;
		margin: 15px 0px;
		background: rgba(255,255,255,1);
		border: 1px solid #666;
		box-shadow: none;
	}

	.reveal section small {
		font-size: 0.8em;
	}

}  
</script>


<script id="pdf-css" type="application/dynamic-css">
    
/**
 * This stylesheet is used to print reveal.js
 * presentations to PDF.
 *
 * https://github.com/hakimel/reveal.js#pdf-export
 */

* {
	-webkit-print-color-adjust: exact;
}

body {
	margin: 0 auto !important;
	border: 0;
	padding: 0;
	float: none !important;
	overflow: visible;
}

html {
	width: 100%;
	height: 100%;
	overflow: visible;
}

/* Remove any elements not needed in print. */
.nestedarrow,
.reveal .controls,
.reveal .progress,
.reveal .playback,
.reveal.overview,
.fork-reveal,
.share-reveal,
.state-background {
	display: none !important;
}

h1, h2, h3, h4, h5, h6 {
	text-shadow: 0 0 0 #000 !important;
}

.reveal pre code {
	overflow: hidden !important;
	font-family: Courier, 'Courier New', monospace !important;
}

ul, ol, div, p {
	visibility: visible;
	position: static;
	width: auto;
	height: auto;
	display: block;
	overflow: visible;
	margin: auto;
}
.reveal {
	width: auto !important;
	height: auto !important;
	overflow: hidden !important;
}
.reveal .slides {
	position: static;
	width: 100%;
	height: auto;

	left: auto;
	top: auto;
	margin: 0 !important;
	padding: 0 !important;

	overflow: visible;
	display: block;

	-webkit-perspective: none;
	   -moz-perspective: none;
	    -ms-perspective: none;
	        perspective: none;

	-webkit-perspective-origin: 50% 50%; /* there isn't a none/auto value but 50-50 is the default */
	   -moz-perspective-origin: 50% 50%;
	    -ms-perspective-origin: 50% 50%;
	        perspective-origin: 50% 50%;
}

.reveal .slides section {
	page-break-after: always !important;

	visibility: visible !important;
	position: relative !important;
	display: block !important;
	position: relative !important;

	margin: 0 !important;
	padding: 0 !important;
	box-sizing: border-box !important;
	min-height: 1px;

	opacity: 1 !important;

	-webkit-transform-style: flat !important;
	   -moz-transform-style: flat !important;
	    -ms-transform-style: flat !important;
	        transform-style: flat !important;

	-webkit-transform: none !important;
	   -moz-transform: none !important;
	    -ms-transform: none !important;
	        transform: none !important;
}

.reveal section.stack {
	margin: 0 !important;
	padding: 0 !important;
	page-break-after: avoid !important;
	height: auto !important;
	min-height: auto !important;
}

.reveal img {
	box-shadow: none;
}

.reveal .roll {
	overflow: visible;
	line-height: 1em;
}

/* Slide backgrounds are placed inside of their slide when exporting to PDF */
.reveal section .slide-background {
	display: block !important;
	position: absolute;
	top: 0;
	left: 0;
	width: 100%;
	z-index: -1;
}

/* All elements should be above the slide-background */
.reveal section>* {
	position: relative;
	z-index: 1;
}

/* Display slide speaker notes when 'showNotes' is enabled */
.reveal .speaker-notes-pdf {
	display: block;
	width: 100%;
	max-height: none;
	left: auto;
	top: auto;
	z-index: 100;
}

/* Display slide numbers when 'slideNumber' is enabled */
.reveal .slide-number-pdf {
	display: block;
	position: absolute;
	font-size: 14px;
}

</script>


<script>
var style = document.createElement( 'style' );
style.type = 'text/css';
var style_script_id = window.location.search.match( /print-pdf/gi ) ? 'pdf-css' : 'paper-css';
var style_script = document.getElementById(style_script_id).text;
style.innerHTML = style_script;
document.getElementsByTagName('head')[0].appendChild(style);
</script>

    
    <link href="presentation_files/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
    <link href="presentation_files/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
    <h1 class="title">Neural Representation of Interaural Time Differences in Humans – the ITD damping function</h1>
    <h2 class="author">Jaime A. Undurraga</h2>
    <h3 class="date">2019-06-29</h3>
</section>

<section><section id="introduction" class="title-slide slide level1"><h1>Introduction</h1></section><section id="cocktail-party-problem-cherry-1953" class="slide level2">
<h2>Cocktail-party problem (Cherry, 1953)</h2>
<p>How do we recognize what one person is saying when others are speaking at the same time?</p>
<p>When everyone at a well-attended party talks at the same level, the speech of the attended talker at a distance of 0.7 m has a signal-to-noise ratio (SNR) of about 0 dB (the background is as intense as the target talker Plomp 1977). This level is sufficient to give adequate intelligibility for listeners with normal hearing (Miller, 1947).</p>
<p><img data-src="./figures/cocktail_party_effect.png" style="width:50.0%" /></p>
</section><section id="auditory-scene-analysis" class="slide level2">
<h2>Auditory scene analysis</h2>
<ul>
<li><p>A critial role of the auditory system is to parse the inputs from the left and right ears into auditory objects - auditory scene analysis. This is an essential role for survival, recognition, and communication.</p></li>
<li><p>Binaural hearing provides cues that allow us to estimate the relative number and location of sources and objects in the environment.</p></li>
<li><p>These cues also help us to estimate the dimensions and characteristics of rooms as well as to hear out speakers in the presence of interfering noise.</p></li>
</ul>
<p><img data-src="./figures/casa_Grothe_2010.png" style="width:50.0%" /></p>
<p>Grothe et al. (2010)</p>
<!-- ##  -->
<!-- >- When the speech sources are spatially separated, normal listeners can perceptually segregate and selectively attend to the source of interest if the sounds arrive from the same location - **spatial release from masking (SRM) ** (Freyman et al., 1999; Brungart, 2001; Freyman -->
<!-- et al., 2001; Hawley et al., 2004) -->
<!-- >- This task is extreamly challenging for listeners with sensorineural hearing loss (with or without hearing aids) or with cochlear implants (Loizou et al., 2009; Marrone et al., 2008). -->
<!-- >- Moreover, listeners with "normal" hearing and elder listeners experience great difficulty when listening in the presence of background noise (Ruggles et al., 2011; Swaminathan et al., 2015; Gallun et al., 2013). -->
<!-- >- Hearing impaired listeners with symmetric binaural hearing often demonstrate reduced SRM primarily due to increased thresholds in spatially separated conditions (Arbogast et al., 2005; Marrone et al., 2008b; Best et al., 2012) -->
</section><section id="which-features-are-conveyed-by-speech-sounds" class="slide level2">
<h2>Which features are conveyed by speech sounds?</h2>
<ul>
<li>Temporal fine structure (TFS)</li>
<li>Envelope information (ENV)</li>
</ul>
<p><img data-src="./figures/temporal-example.png" style="width:70.0%" /></p>
</section><section id="binaural-cues" class="slide level2">
<h2>Binaural cues</h2>
<p>When listening to sounds, we rely on three mechanisms for both sound localization and auditory scene analysis</p>
<ul>
<li>Interaural level differences (ILDs)</li>
<li>Interaural time differences (ITDs)</li>
<li>Interaural coherence</li>
</ul>
<p><img data-src="./figures/itd_ild_cartoon.png" style="width:60.0%" /></p>
</section><section id="envelope-itds" class="slide level2">
<h2>Envelope ITDs</h2>
<ul>
<li></li>
</ul>
<p><img data-src="./figures/itd_env_0_5.png" /> <img data-src="./figures/itd_env_2_0.png" /></p>
<!-- ## Localization using ITDs -->
<!-- <img class="fragment" data-fragment-index="0" src="./figures/azimuth_itd.png" width="40%"> -->
<!-- <img class="fragment" data-fragment-index="1" src="./figures/itd_ir.png" width="50%"> -->
<!-- <li class="fragment" data-fragment-index="2">  -->
<!-- ITDs within the physiological range experienced by human listeners are about ±760 μs; (e.g. Constan and Hartmann (2003) and Hartmann and Macaulay (2014)) </li> -->
<!-- <li class="fragment" data-fragment-index="3"> -->
<!-- ITDs (using fine structure) are useful for frequencies below  1500 Hz -->
<!-- </li> -->
<!-- <li class="fragment" data-fragment-index="4"> -->
<!-- ITDs in the envelope of the signal are also used to determine the location of a source in both lower and higher frequencies. -->
<!-- </li> -->
<!-- ## The precedence effect -->
<!-- <img src="./figures/precedence_effect_cartoon.png" width="80%"> -->
<!-- <br> -->
<!-- (Dietz et al. 2013) -->
<!-- <li class="fragment" data-fragment-index="0">  -->
<!-- A single auditory event is perceived at the direction of the first direct wave front (2 and 50 ms later, even when reflections are 10 dB louder) -->
<!-- </li> -->
<!-- <li class="fragment" data-fragment-index="1"> -->
<!-- Asymmetric hearing loss, hearing impairment and ageing negatively affect the precedence effect (Akeroyd and Guy, -->
<!-- 2011). This can only partially restored by hearing aids. -->
<!-- </li> -->
<!-- # Binaural processing and speech understanding -->
<!-- ## Binaural Redundancy -->
<!-- - Loudness doubles when the two ears are used instead of one ear for a sound coming from the front of the listener (a single ear would require an increase of about 10 dB; Fletcher and Munson, 1933) -->
<!-- - Just noticeable differences in intensity and frequency improve with signal redundancy -->
<!-- - Speech recognition in the presence of background noise improves (Marrone 2008, Neher 2009) -->
<!-- - Hearing impairment may lead to a slightly weaker binaural benefit in patients  (Dillon, 2001) -->
<!-- - Binaural stimulation sounds can be louder than with a monaural presentation without causing discomfort (even true for CI-treated patient) -->
<!-- ## Binaural Release from Masking (or Binaural Squelch; or Hirsh effect) -->
<!-- <img class="fragment" data-fragment-index="0" src="./figures/bmld_cartoon_n0s0.png" width="45%" data-audio-src="./audio/convolved/sinusoidal_arctic_a0002_d_type_noise_target_0_d1_0_d2_0_snr_-10.wav" data-audio-advance=-1 data-audio-advance=-1 > -->
<!-- <img class="fragment" data-fragment-index="1" src="./figures/bmld_cartoon_n0spi.png" width="45%" data-audio-src="./audio/convolved/sinusoidal_arctic_a0002_d_type_noise_target_0_d1_90_d2_-90_snr_-10.wav" data-audio-advance=-1 data-audio-advance=-1> -->
<!-- <li class="fragment" data-fragment-index="2"> Binaural release from masking may improve detection threshold up to about 16 dB for frequencies around 250 Hz and around 3 dB at 1500 Hz </li> -->
<!-- ## Spatial Release from Masking   -->
<!-- <img class="fragment" data-fragment-index="0" src="./figures/bmld_cartoon_srm_front.png" width="45%" data-audio-src="./audio/convolved/convolved_arctic_a0002_d_type_speech_target_0_d1_0_d2_0_snr_0.wav" data-audio-advance=-1 data-audio-advance=-1 > -->
<!-- <img class="fragment" data-fragment-index="1" src="./figures/bmld_cartoon_srm.png" width="45%" data-audio-src="./audio/convolved/convolved_arctic_a0002_d_type_speech_target_0_d1_-80_d2_80_snr_0.wav" data-audio-advance=-1 data-audio-advance=-1> -->
<!-- <li class="fragment" data-fragment-index="2">  -->
<!-- Binaural release from masking may improve detection thresholds up to 12 dB for multiple speech interferers (Jones and Litovsky, 2011), and facilitates source segregation provided that streaming can build up and natural onset cues are present (Drennan, Gatehouse, and Lever, 2003). -->
<!-- </li> -->
<!-- <li class="fragment" data-fragment-index="3">  -->
<!-- Segregation is always better for the combination of both ITDs and ILDs cues (Culling, Hawley, and Litovsky 2004) -->
<!-- </li> -->
<!-- <li class="fragment" data-fragment-index="4">  -->
<!-- A separation of only 10° between two voices is already strong enough to allow segregation  (Brungart and Simpson, 2007). -->
<!-- </li> -->
<!-- <li class="fragment" data-fragment-index="5"> ITD is a critical spatial cue for sound localization and speech perception in noise (Bronkhorst & -->
<!-- Plomp, 1988; Wightman & Kistler, 1992). -->
<!-- </li> -->
</section></section>
<section><section id="autditory-pathway" class="title-slide slide level1"><h1>Autditory Pathway</h1></section><section id="section" class="slide level2">
<h2></h2>
<p>Input to one ear ——————-&gt; output at the auditory nerve</p>
<p><img data-src="./figures/spectrogram_cheap.png" style="width:60.0%" /> <img data-src="./figures/raster.png" style="width:35.0%" /></p>
</section><section id="auditory-pathway" class="slide level2">
<h2>Auditory pathway</h2>
<p><img data-src="./figures/auditory_pathway.png" style="width:50.0%" /></p>
<p>(Amunts, K. et al. 2012)</p>
<!-- ## ILD pathway -->
<!-- ![](./figures/ild_pathway.svg){width=80%} -->
<!-- (Grothe et al. 2010) -->
<!-- <li class="fragment" data-fragment-index="0"> -->
<!-- The initial site of ILD processing is generally considered to be the LSO. -->
<!-- </li> -->
<!-- <li class="fragment" data-fragment-index="1"> -->
<!-- LSO are innervated by direct excitatory ipsilateral inputs from spherical bushy cells and inhibitory inputs indirectly originating from the globular bushy cells. -->
<!-- </li> -->
</section><section id="itd-pathway" class="slide level2">
<h2>ITD pathway</h2>
<p><img data-src="./figures/itd_pathway.svg" style="width:80.0%" /></p>
<p>(Grothe et al. 2010)</p>
<li class="fragment" data-fragment-index="0">
The initial site of ITD processing is considered to be the MSO.
</li>
<li class="fragment" data-fragment-index="1">
MSO are innervated by direct excitatory ipsi- anc contra-lateral inputs from spherical bushy cells and inhibitory inputs indirectly originating from the globular bushy cells.
</li>
</section></section>
<section><section id="models-for-itd-processing" class="title-slide slide level1"><h1>Models for ITD processing</h1></section><section id="neural-density" class="slide level2">
<h2>Neural density</h2>
<ul>
<li><span class="math inline">\(\pi\)</span>-limit</li>
<li>straightness-weighting (weighted-image model)</li>
</ul>
<p><img data-src="./figures/neural_density.png" style="width:80.0%" /></p>
<p>(McAlpine et al. 2001; Stern and Shear 1996)</p>
<!-- - Peaks of the cross-correlograms at –1.5 ms < peaks closer to 0 - central weighting. -->
<!-- - Correct localization estimated from second processing level (in the inferior colliculus, gray curve on top of each panel). -->
</section><section id="section-1" class="slide level2">
<h2></h2>
<p><img data-src="./figures/neural_density_stern_shear_itd_0.5.png" style="width:80.0%" /></p>
</section><section id="section-2" class="slide level2">
<h2></h2>
<p><img data-src="./figures/neural_density_stern_shear_itd_1.0.png" style="width:80.0%" /></p>
</section><section id="section-3" class="slide level2">
<h2></h2>
<p><img data-src="./figures/neural_density_stern_shear_itd_1.5.png" style="width:80.0%" /></p>
</section><section id="section-4" class="slide level2">
<h2></h2>
<p><img data-src="./figures/neural_density_stern_shear_itd_2.0.png" style="width:80.0%" /></p>
</section><section id="section-5" class="slide level2">
<h2></h2>
<p><img data-src="./figures/neural_density_stern_shear_itd_2.5.png" style="width:80.0%" /></p>
</section><section id="section-6" class="slide level2">
<h2></h2>
<p><img data-src="./figures/neural_density_stern_shear_itd_3.0.png" style="width:80.0%" /></p>
</section><section id="section-7" class="slide level2">
<h2></h2>
<p><img data-src="./figures/neural_density_stern_shear_itd_3.5.png" style="width:80.0%" /></p>
</section><section id="section-8" class="slide level2">
<h2></h2>
<p><img data-src="./figures/neural_density_stern_shear_itd_4.0.png" style="width:80.0%" /></p>
<!-- ## -->
<!-- Thompson et al. (2006)  -->
<!-- <img src="./figures/thompson_2006_2.png" width="80%"> -->
<!-- - Inferior colliculus consistent with centrality. -->
<!-- - Cortical responses to sounds with ITDs within the $\pi$-limit are in line with the predictions of both models.  -->
<!-- - However, neural activation is bilateral for "long" ITDs, despite these being perceived as clearly lateralized -->
<!-- - Long ITDs leads to higher activation in cortex than processing of short ITDs. -->
<!-- ##  -->
<!-- Kriegstein et al. (2008) -->
<!-- <img src="./figures/kriegstein_2008_1.png" width="40%"> -->
<!-- - human and animal Magnetoencephalography (MEG) recordings as well as computational models with ITD detectors restricted either to ±π or with their best ITDs well beyond ±π but with strong weighting to ITDs near zero - *“central-weighting”* agree with a limited range of ITD detectors (Salminen et al., 2018; Stern and Shear, 1996). -->
</section></section>
<section><section id="neurophysiological-binaural-processing-in-humans" class="title-slide slide level1"><h1>Neurophysiological binaural processing in humans</h1></section><section id="eeg-experiments" class="slide level2">
<h2>EEG Experiments</h2>
<p><img src="./figures/eeg_setting.png" width="60%"></p>
<p><img src="./figures/software_biosemi_01_large.jpg" width="60%"></p>
<ul>
<li>Binaural recordings were obtained from 10 NH participants.</li>
<li>64 + 2 + 2 channels recording (amplifier: Biosemi ActiveTwo system).</li>
<li>Fs: 16 384 kHz / 24 bits (Lowpass: 3 kHz)</li>
</ul>
</section><section id="methods" class="slide level2">
<h2>Methods</h2>
<p>Objective measures of binaural processing can be obtained by using stimuli where the temporal structure is manipulated so that the perceived location of the sound image changes periodically (e.g. 6.7 Hz) over time.</p>
<p><img data-src="./figures/stimulus_example.png" style="width:55.0%" /></p>
<ul>
<li>Simuli consisted of narrow-bandpass noise (300 - 700 Hz) at 75 dB SPL</li>
</ul>
</section><section id="section-9" class="slide level2">
<h2></h2>
<div class="column" style="float:left; width:50%; text-align: center">
By swithcing the “sound image” from left to right at 6.7 Hz, a strong steady-state response is evoked at that particular frequency
</li>
<li class="fragment" data-fragment-index="0">
ITM-FRs are larger when the stimuli causes a strong lateralization percept.
</li>
</div>
<div class="column" style="float:right; width:50%; text-align: center">
<ul class="fragment" data-fragment-index="1">
<video width="320" height="240" controls source src="./figures/example0.5_-0.5.mp4" type="video/mp4">
</ul>
</div>
<!-- ## Neural representation of asymmetric interaural time modulations (ITMs) -->
<!-- - ITMs: 0/ + 0.5 ms, 0/ + 1.5 ms, 0/ + 2.0 ms, 0/ + 3.0 ms, 0/ + 4.0 ms. -->
<!-- <img src="./figures/average-itds-zero-ref.png" width="40%"> -->
<!-- <img src="./figures/itm-fr-asym-scalp.png" width="11%"> -->
<!-- ##  -->
<!-- <img src="./figures/itm-fr-coherence-zero-ref-gfp.png" width="40%"> -->
<!-- <img src="./figures/itm-fr-zero-ref-diff.png" width="35%"> -->
<!-- # Testing the independence of ITD detectors -->
<!-- ## -->
<!-- - ITMs: −0.5/ + 0.5 ms -->
<!-- <img src="./figures/neural_density_stern_shear_itd_-0.5.png" width="45%"> -->
<!-- <img src="./figures/neural_density_stern_shear_itd_0.5.png" width="45%"> -->
<!-- - the ITM between −0.5 ms and −0.5 ms should be less adapted (different neural activation) -->
<!-- ## -->
<!-- - ITMs: −0.5/ + 1.5 ms -->
<!-- <img src="./figures/neural_density_stern_shear_itd_-0.5.png" width="45%"> -->
<!-- <img src="./figures/neural_density_stern_shear_itd_1.5.png" width="45%"> -->
<!-- - the ITM between −0.5 ms and 1.5 ms should be more adapted (common neural activation) -->
<!-- ## -->
<!-- - ITMs: +0.5/ + 1.5 ms. -->
<!-- <img src="./figures/neural_density_stern_shear_itd_0.5.png" width="45%"> -->
<!-- <img src="./figures/neural_density_stern_shear_itd_1.5.png" width="45%"> -->
<!-- - the ITM between +0.5 ms and +1.5 ms should be less adapted (different neural activation) -->
<!-- ## Results  -->
<!-- <div class="column" style="float:left; width:50%; text-align: center"> -->
<!-- <img src="./figures/itm-fr-adaptation-gfp.png" width="70%"> -->
<!-- </div> -->
<!-- <div class="column" style="float:right; width:50%; text-align: center"> -->
<!-- <img src="./figures/itm-fr-adaptation-gfp-diff.png" width="80%"> -->
<!-- </div> -->
<!-- <img src="./figures/Salminen_2018.png" width="30%"> -->
<!-- <br> -->
<!-- Salminen et al. 2018 -->
</section><section id="neural-representation-of-symmetric-itms" class="slide level2">
<h2>Neural representation of symmetric ITMs</h2>
<p><img src="./figures/average-itds-coherence.png" width="50%"> <img src="./figures/scalp_map_coherence.png" width="8.2%"></p>
</section><section id="neural-representation-of-symmetric-itms-1" class="slide level2">
<h2>Neural representation of symmetric ITMs</h2>
<ul>
<li>ITMs: −0.5/ + 0.5 ms, −1.0/ + 1.0 ms, −1.5/ + 1.5 ms, −2.0/ + 2.0 ms, −2.5/ + 2.5 ms, −3.0/ + 3.0 ms, −4.0/ + 4.0 ms</li>
</ul>
<p><img src="./figures/itm-fr-coherence-gfp.png" width="50%"> <img src="./figures/itm-fr-coherence.png" width="40%"></p>
</section><section id="fnirs-experiments" class="slide level2">
<h2>FNIRs Experiments</h2>
<ul>
<li>10 Participants</li>
<li>Same ITMs as in EEG: −0.5/ + 0.5 ms, −1.0/ + 1.0 ms, −1.5/ + 1.5 ms, −2.0/ + 2.0 ms, −2.5/ + 2.5 ms, −3.0/ + 3.0 ms, −4.0/ + 4.0 ms <strong>(6.7 Hz)</strong></li>
<li>Simuli consisted of narrow-bandpass noise (300 - 700 Hz) at 75 dB SPL</li>
<li>fNIRs were elicited by presenting 25 trials of 6 seconds separated by 15-30 s of silence.</li>
<li>16 LED light sources and 16 avalanche photo-diode light detectors (NIRScout, NIRX, Germany)</li>
<li>Fs: 7 Hz</li>
</ul>
<p><img data-src="./figures/fNIRS.jpeg" style="width:50.0%" /></p>
</section><section id="results" class="slide level2">
<h2>Results</h2>
<p><img data-src="./figures/fnirs_average_hbo_hbr.jpg" style="width:30.0%" /> <img data-src="./figures/fnirs_itd_hbo.jpg" style="width:50.0%" /></p>
</section><section id="results-1" class="slide level2">
<h2>Results</h2>
<p><img data-src="./figures/fnirs_optodes_responses.jpg" style="width:100.0%" /></p>
</section><section id="eeg-and-fnirs" class="slide level2">
<h2>EEG and fNIRS</h2>
<p><img data-src="./figures/robust_correlation_eeg_fnirs.png" style="width:50.0%" /></p>
</section><section id="neural-representation-from-a-model" class="slide level2">
<h2>Neural representation from a model</h2>
<div class="column" style="float:left; width:50%; text-align: right">
<p><img src="./figures/ave_adapted_neural_activity_pi_limit_probe_-0.5_800.0_1400.0.png" width="100%"> <br> Activation difference using Salminen <span class="math inline">\(\pi\)</span>-limit</p>
<p><img src="./figures/ave_adapted_neural_activity_pi_limit_probe_-0.5_300.0_700.0.png" width="100%"> <br> Activation difference using Salminen <span class="math inline">\(\pi\)</span>-limit</p>
</div>
<div class="column" style="float:right; width:50%; text-align: center">
<p><img src="./figures/ave_adapted_neural_activity_pi_limit_undurraga_sym.png" width="100%"> <br> Activation difference my data (rms) activity <span class="math inline">\(\pi\)</span>-limit</p>
</div>
</section><section id="predicted-average-neural-activity" class="slide level2">
<h2>Predicted average neural activity</h2>
<div class="column" style="float:left; width:45%; text-align: right">
<p><img src="./figures/rms_neural_activity_pi_limit.png" width="80%"> <br> Average activity <span class="math inline">\(\pi\)</span>-limit (stimuli leading on left) <br> <img src="./figures/rms_diff_neural_activity_pi_limit.png" width="80%"> <br> Activation difference (rms) activity <span class="math inline">\(\pi\)</span>-limit</p>
</div>
<div class="column" style="float:right; width:45%; text-align: right">
<p><img src="./figures/rms_neural_activity_stern_shear.png" width="80%"> <br> Average activity central weighting (stimuli leading on left) <br> <img src="./figures/rms_diff_neural_activity_stern_shear.png" width="80%"> <br> Activation difference (rms) central weighting</p>
</div>
</section><section id="results-2" class="slide level2">
<h2>Results</h2>
<div class="column" style="float:left; width:40%; text-align: center">
<p><img src="./figures/itm-fr-coherence-gfp.png" width="100%"></p>
<ul>
<li><p>Significant effect of the ITM (F(7,56.4) = 6.6, p &lt; 0.001).</p></li>
<li>The damping pattern may result by the trade-off between conflicting envelope and fine structure ITD. Whilst the envelope has a consistent ITD across all conditions, the interaural phase difference (IPD) of the 500 Hz carrier does not.</li>
</ul>
</div>
<div class="column" style="float:left; width:60%; text-align: left">
<p><img class="fragment" data-fragment-index="1" src="./figures/itd_env_0_5.png" width="40%"> <img class="fragment" data-fragment-index="2" src="./figures/itd_env_1_0.png" width="40%"></p>
<p><img class="fragment" data-fragment-index="3" src="./figures/itd_env_1_5.png" width="40%"> <img class="fragment" data-fragment-index="4" src="./figures/itd_env_2_0.png" width="40%"></p>
</div>
<li class="fragment" data-fragment-index="1">
At −0.5/ + 0.5 ms (−90 ◦ / 90 ◦ IPD), the IPD of the centre frequency is consistent with the envelope ITD.
</li>
<li class="fragment" data-fragment-index="2">
At −1.0/ + 1.0 ms (−180 ◦ / 180 ◦ IPD), the IPD of the centre frequency is ambiguous.
</li>
<li class="fragment" data-fragment-index="3">
At −1.5/ + 1.5 ms (−270 ◦ / 270 ◦ IPD), the IPD of the centre frequency is conflicting with the envelope ITD, i.e. the fine structure IPD leads in the right ear whilst the envelope ITD leads on the left ear.
</li>
<li class="fragment" data-fragment-index="4">
At −2.0/ + 2.0 ms (−360 ◦ / 360 ◦ IPD), there is not IPD in the fine structure at the centre frequency, and so no conflicting cues.
</li>
</section><section id="section-10" class="slide level2">
<h2></h2>
<p><img class="fragment" data-fragment-index="1" src="./figures/instantaneous_itd.png" width="100%"></p>
</section><section id="conclusions" class="slide level2">
<h2>Conclusions</h2>
<li class="fragment" data-fragment-index="0" style="text-align: left">
ITMs could be reliable recorded from all participants across conditions.
</li>
<li class="fragment" data-fragment-index="1" style="text-align: left">
Asymmetric ITMs showed large and consistent responses with a damping pattern at ITMs with ITDs multiple of the central frequency of the noise.
</li>
<li class="fragment" data-fragment-index="2" style="text-align: left">
Similarly ITMs showed a decreasing damping function. The damping function is consistent with conflicting cues between the envelope and the fine structure of the signal.
</li>
<li class="fragment" data-fragment-index="3" style="text-align: left">
<p>The adaptor paradigm in Experiment 2 could be also explained by conflictive processing between envelope and fine structure.</p>
<p>At −0.5/ + 0.5 ms (−90 ◦ / 90 ◦ IPD), the IPD of the centre frequency is consistent with the envelope ITD.</p>
<p>At −0.5/ + 1.5 ms (−90 ◦ / 270 ◦ IPD), the IPD of the centre frequency does not change, whilst the envelope ITD does.</p>
At +0.5/ + 1.5 ms (90 ◦ / 270 ◦ IPD), the IPD of the centre frequency effectively changes between 90 ◦ and −90 ◦ , whilst the envelope ITD is always leading on the right ear.
</li>
</section><section id="acknowledgments" class="slide level2">
<h2>Acknowledgments</h2>
<ul>
<li>Australian Research Council [project number FL160100108]</li>
<li>Thanks to you for “listening”</li>
</ul>
<p><img src="./figures/ahh.jpg" width="60%"> <br> <img src="./figures/ahh_team.jpg" width="60%"></p>
<!-- ## References -->
</section></section>
    </div>
  </div>

  <script src="presentation_files/reveal.js-3.3.0.1/lib/js/head.min.js"></script>
  <script src="presentation_files/reveal.js-3.3.0.1/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Display a presentation progress bar
        progress: true,
        // Display the page number of the current slide
        slideNumber: true,
        // Push each slide change to the browser history
        history: true,
        // Vertical centering of slides
        center: false,
        // Opens links in an iframe preview overlay
        previewLinks: true,
        // Transition style
        transition: 'fade', // none/fade/slide/convex/concave/zoom
        // Transition style for full page slide backgrounds
        backgroundTransition: 'default', // none/fade/slide/convex/concave/zoom



        chalkboard: {
          toggleNotesButton: true,
        },

        keyboard: {
          67: function() { RevealChalkboard.toggleNotesCanvas() },    // toggle notes canvas when 'c' is pressed
          66: function() { RevealChalkboard.toggleChalkboard() }, // toggle chalkboard when 'b' is pressed
          46: function() { RevealChalkboard.clear() },    // clear chalkboard when 'DEL' is pressed
           8: function() { RevealChalkboard.reset() },    // reset chalkboard data on current slide when 'BACKSPACE' is pressed
          68: function() { RevealChalkboard.download() }, // downlad recorded chalkboard drawing when 'd' is pressed
        },

        // Optional reveal.js plugins
        dependencies: [
          { src: 'presentation_files/reveal.js-3.3.0.1/plugin/notes/notes.js', async: true },
          { src: 'presentation_files/reveal.js-3.3.0.1/plugin/zoom-js/zoom.js', async: true },
          { src: 'presentation_files/reveal.js-3.3.0.1/plugin/chalkboard/chalkboard.js', async: true },
        ]
      });
    </script>
  <!-- dynamically load mathjax for compatibility with self-contained -->
  <script>
    (function () {
      var script = document.createElement("script");
      script.type = "text/javascript";
      script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
      document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>

<script>
  (function() {
    if (window.jQuery) {
      Reveal.addEventListener( 'slidechanged', function(event) {  
        window.jQuery(event.previousSlide).trigger('hidden');
        window.jQuery(event.currentSlide).trigger('shown');
      });
    }
  })();
</script>

<script>
 Reveal.initialize({
    // Optional reveal.js plugins
    dependencies: [
        { src: './reveal.js-plugins-master/audio-slideshow/slideshow-recorder.js', condition: function( ) { return !!document.body.classList; } },	
		{ src: './reveal.js-plugins-master/audio-slideshow/audio-slideshow.js', condition: function( ) { return !!document.body.classList; } },
    ], 
    audio: {
		prefix: 'audio/', 	// audio files are stored in the "audio" folder
		suffix: '.wav',		// audio files have the ".ogg" ending
		textToSpeechURL: null,  // the URL to the text to speech converter
		defaultNotes: false, 	// use slide notes as default for the text to speech converter
		defaultText: false, 	// use slide text as default for the text to speech converter
		advance: 0, 		// advance to next slide after given time in milliseconds after audio has played, use negative value to not advance 
		autoplay: false,	// automatically start slideshow
		defaultDuration: 5,	// default duration in seconds if no audio is available 
		playerOpacity: 0.05,	// opacity value of audio player if unfocused
		playerStyle: 'position: fixed; bottom: 4px; left: 25%; width: 50%; height:75px; z-index: 33;', // style used for container of audio controls 
		startAtFragment: false, // when moving to a slide, start at the current fragment or at the start of the slide
	},
});
</script>

  </body>
</html>
